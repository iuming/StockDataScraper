name: Enhanced Stock Data Scraper

on:
  schedule:
    # æ¯ä¸ªå·¥ä½œæ—¥å‡Œæ™¨2ç‚¹UTCè¿è¡Œï¼ˆåŒ—äº¬æ—¶é—´10ç‚¹ï¼‰
    - cron: '0 2 * * 1-5'
  workflow_dispatch:
    inputs:
      tickers:
        description: 'è‚¡ç¥¨ä»£ç ï¼ˆé€—å·åˆ†éš”ï¼‰'
        required: false
        default: 'AAPL,MSFT,GOOGL,TSLA,NVDA'
      start_date:
        description: 'å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)'
        required: false
        default: '2024-01-01'
      force_update:
        description: 'å¼ºåˆ¶æ›´æ–°ï¼ˆå³ä½¿æ— æ–°æ•°æ®ï¼‰'
        type: boolean
        required: false
        default: false

# æ·»åŠ æƒé™è®¾ç½®
permissions:
  contents: write
  issues: write
  pull-requests: read

jobs:
  scrape-stocks:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # è·å–å®Œæ•´å†å²è®°å½•

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Check existing data
      id: check_data
      run: |
        if [ -f "stock_data.csv" ]; then
          lines=$(wc -l < stock_data.csv)
          echo "existing_lines=$lines" >> $GITHUB_OUTPUT
          echo "Found existing data with $lines lines"
        else
          echo "existing_lines=0" >> $GITHUB_OUTPUT
          echo "No existing data file found"
        fi

    - name: Run stock scraper
      id: scrape
      run: |
        # è®¾ç½®ç¯å¢ƒå˜é‡
        export TICKERS="${{ github.event.inputs.tickers || 'AAPL,MSFT,GOOGL,TSLA,NVDA' }}"
        export START="${{ github.event.inputs.start_date || '2024-01-01' }}"
        
        echo "Running scraper with TICKERS=$TICKERS, START=$START"
        
        # è¿è¡Œè„šæœ¬å¹¶æ•è·è¾“å‡º
        python scrape_stock_akshare.py > scrape_output.log 2>&1
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if [ $? -eq 0 ]; then
          echo "scrape_success=true" >> $GITHUB_OUTPUT
          echo "Scraping completed successfully"
        else
          echo "scrape_success=false" >> $GITHUB_OUTPUT
          echo "Scraping failed"
          cat scrape_output.log
          exit 1
        fi

    - name: Check for new data
      id: check_new
      run: |
        if [ -f "stock_data.csv" ]; then
          new_lines=$(wc -l < stock_data.csv)
          old_lines="${{ steps.check_data.outputs.existing_lines }}"
          
          if [ "$new_lines" -gt "$old_lines" ] || [ "${{ github.event.inputs.force_update }}" = "true" ]; then
            echo "has_new_data=true" >> $GITHUB_OUTPUT
            echo "New data detected: $old_lines -> $new_lines lines"
          else
            echo "has_new_data=false" >> $GITHUB_OUTPUT
            echo "No new data to commit"
          fi
        else
          echo "has_new_data=false" >> $GITHUB_OUTPUT
        fi

    - name: Generate data summary
      if: steps.check_new.outputs.has_new_data == 'true'
      run: |
        echo "## ğŸ“Š æ•°æ®æ›´æ–°æ‘˜è¦" > update_summary.md
        echo "" >> update_summary.md
        echo "- **æ›´æ–°æ—¶é—´**: $(date +'%Y-%m-%d %H:%M:%S UTC')" >> update_summary.md
        echo "- **è‚¡ç¥¨ä»£ç **: ${{ github.event.inputs.tickers || 'AAPL,MSFT,GOOGL,TSLA,NVDA' }}" >> update_summary.md
        echo "- **æ•°æ®è¡Œæ•°**: $(wc -l < stock_data.csv)" >> update_summary.md
        echo "- **æ–‡ä»¶å¤§å°**: $(du -h stock_data.csv | cut -f1)" >> update_summary.md
        echo "" >> update_summary.md
        
        # æ˜¾ç¤ºæœ€æ–°å‡ æ¡è®°å½•
        echo "### ğŸ“ˆ æœ€æ–°æ•°æ®é¢„è§ˆ" >> update_summary.md
        echo '```' >> update_summary.md
        tail -5 stock_data.csv >> update_summary.md
        echo '```' >> update_summary.md

    - name: Commit and push changes
      if: steps.check_new.outputs.has_new_data == 'true'
      run: |
        git config --local user.email "6ming@hrbeu.edu.cn"
        git config --local user.name "iuming"
        
        # æ·»åŠ æ–‡ä»¶
        git add stock_data.csv
        
        # åˆ›å»ºæäº¤ä¿¡æ¯
        commit_msg="ğŸ“Š Auto-update stock data - $(date +'%Y-%m-%d')"
        commit_msg="$commit_msg

        $(cat update_summary.md)"
        
        git commit -m "$commit_msg"
        git push

    - name: Upload logs as artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs-${{ github.run_number }}
        path: |
          scrape_output.log
          update_summary.md
        retention-days: 7

    - name: Create Issue on Failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const title = `ğŸš¨ Stock Scraper Failed - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## é”™è¯¯è¯¦æƒ…
          
          - **å·¥ä½œæµ**: ${context.workflow}
          - **è¿è¡ŒID**: ${context.runId}
          - **å¤±è´¥æ—¶é—´**: ${new Date().toISOString()}
          - **è§¦å‘æ–¹å¼**: ${context.eventName}
          
          ## å¯èƒ½åŸå› 
          
          1. ç½‘ç»œè¿æ¥é—®é¢˜
          2. akshare API é™åˆ¶
          3. æ•°æ®æ ¼å¼å˜æ›´
          4. GitHub Actions ç¯å¢ƒé—®é¢˜
          
          ## ä¸‹ä¸€æ­¥
          
          è¯·æ£€æŸ¥ [Actions æ—¥å¿—](${context.payload.repository.html_url}/actions/runs/${context.runId}) è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚
          `;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: body,
            labels: ['bug', 'automation']
          });
